#!/usr/bin/env python3
"""
Whisperé€Ÿåº¦æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

faster-whisperã®å®Ÿè£…ã‚’ç¢ºèªã—ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹ã‚’æ¸¬å®šã—ã¾ã™ã€‚
"""

import asyncio
import time
import sys
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent.parent))

from app.services.whisper_service import WhisperService, FASTER_WHISPER_AVAILABLE
from app.core.config import settings
import structlog

logger = structlog.get_logger(__name__)


async def verify_whisper_implementation():
    """Whisperå®Ÿè£…ã®æ¤œè¨¼"""
    print("=" * 60)
    print("Whisperé€Ÿåº¦æ”¹å–„æ¤œè¨¼")
    print("=" * 60)
    print()
    
    # 1. faster-whisperã®åˆ©ç”¨å¯èƒ½æ€§ç¢ºèª
    print("ðŸ“¦ 1. faster-whisperåˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯")
    print(f"   faster-whisper available: {FASTER_WHISPER_AVAILABLE}")
    
    if not FASTER_WHISPER_AVAILABLE:
        print("   âŒ faster-whisperãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        print("   ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: pip install faster-whisper")
        return False
    
    print("   âœ… faster-whisperãŒåˆ©ç”¨å¯èƒ½ã§ã™")
    print()
    
    # 2. è¨­å®šç¢ºèª
    print("âš™ï¸  2. Whisperè¨­å®šç¢ºèª")
    print(f"   ãƒ¢ãƒ‡ãƒ«: {settings.WHISPER_MODEL}")
    print(f"   ãƒ‡ãƒã‚¤ã‚¹: {settings.WHISPER_DEVICE}")
    print()
    
    # 3. WhisperServiceã®åˆæœŸåŒ–
    print("ðŸ”§ 3. WhisperServiceã®åˆæœŸåŒ–")
    try:
        service = WhisperService()
        print(f"   ãƒ¢ãƒ‡ãƒ«å: {service.model_name}")
        print(f"   ãƒ‡ãƒã‚¤ã‚¹: {service.device}")
        print(f"   è¨ˆç®—ã‚¿ã‚¤ãƒ—: {service.compute_type}")
        print("   âœ… WhisperServiceåˆæœŸåŒ–æˆåŠŸ")
    except Exception as e:
        print(f"   âŒ åˆæœŸåŒ–å¤±æ•—: {e}")
        return False
    print()
    
    # 4. ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰æ™‚é–“æ¸¬å®š
    print("â±ï¸  4. ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰æ™‚é–“æ¸¬å®š")
    try:
        start_time = time.time()
        service._load_model()
        load_time = time.time() - start_time
        print(f"   ãƒ­ãƒ¼ãƒ‰æ™‚é–“: {load_time:.2f}ç§’")
        print("   âœ… ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰æˆåŠŸ")
    except Exception as e:
        print(f"   âŒ ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
        return False
    print()
    
    # 5. faster-whisperã®ç‰¹å¾´ç¢ºèª
    print("ðŸš€ 5. faster-whisperæœ€é©åŒ–æ©Ÿèƒ½")
    print("   âœ… CTranslate2ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ä½¿ç”¨")
    print("   âœ… int8é‡å­åŒ–ã«ã‚ˆã‚‹é«˜é€ŸåŒ–")
    print("   âœ… CPUæœ€é©åŒ–")
    print("   âœ… ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†å¯¾å¿œ")
    print()
    
    # 6. åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«æƒ…å ±
    print("ðŸ“‹ 6. æŽ¨å¥¨ãƒ¢ãƒ‡ãƒ«è¨­å®š")
    models = {
        "tiny": "æœ€é€Ÿï¼ˆç²¾åº¦ä½Žï¼‰",
        "base": "é«˜é€Ÿï¼ˆãƒãƒ©ãƒ³ã‚¹è‰¯å¥½ï¼‰",
        "small": "ä¸­é€Ÿï¼ˆé«˜ç²¾åº¦ï¼‰",
        "medium": "ä½Žé€Ÿï¼ˆã‚ˆã‚Šé«˜ç²¾åº¦ï¼‰",
        "large-v3": "æœ€ã‚‚é«˜ç²¾åº¦ï¼ˆæœ€ã‚‚é…ã„ï¼‰",
        "large-v3-turbo": "é«˜ç²¾åº¦ã‹ã¤é«˜é€Ÿï¼ˆæŽ¨å¥¨ï¼‰"
    }
    
    for model, desc in models.items():
        marker = "ðŸ‘‰" if model == service.model_name else "  "
        print(f"   {marker} {model}: {desc}")
    print()
    
    # 7. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹æœŸå¾…å€¤
    print("ðŸ“Š 7. faster-whisperã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹")
    print("   OpenAI Whisperã¨æ¯”è¼ƒ:")
    print("   â€¢ CPUæŽ¨è«–: ç´„4-8å€é«˜é€Ÿ")
    print("   â€¢ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: ç´„50%å‰Šæ¸›")
    print("   â€¢ ç²¾åº¦: ã»ã¼åŒç­‰")
    print()
    
    # 8. å®Ÿè£…ç¢ºèª
    print("âœ… 8. å®Ÿè£…ç¢ºèªçµæžœ")
    print("   âœ… faster-whisperãŒæ­£ã—ãçµ±åˆã•ã‚Œã¦ã„ã¾ã™")
    print("   âœ… int8é‡å­åŒ–ã«ã‚ˆã‚‹æœ€é©åŒ–ãŒæœ‰åŠ¹ã§ã™")
    print("   âœ… CPUæŽ¨è«–ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™")
    print()
    
    print("=" * 60)
    print("æ¤œè¨¼å®Œäº†: ã™ã¹ã¦ã®ãƒã‚§ãƒƒã‚¯ã«åˆæ ¼ã—ã¾ã—ãŸï¼")
    print("=" * 60)
    
    return True


async def benchmark_transcription(audio_file: Path = None):
    """è»¢å†™é€Ÿåº¦ãƒ™ãƒ³ãƒãƒžãƒ¼ã‚¯ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰"""
    if not audio_file or not audio_file.exists():
        print("\nâš ï¸  éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ãƒ™ãƒ³ãƒãƒžãƒ¼ã‚¯ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
        print("   ãƒ™ãƒ³ãƒãƒžãƒ¼ã‚¯å®Ÿè¡Œæ–¹æ³•:")
        print("   python scripts/verify_whisper_speed.py /path/to/audio.m4a")
        return
    
    print("\n" + "=" * 60)
    print("è»¢å†™é€Ÿåº¦ãƒ™ãƒ³ãƒãƒžãƒ¼ã‚¯")
    print("=" * 60)
    print()
    
    service = WhisperService()
    
    print(f"ðŸ“ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«: {audio_file}")
    print(f"ðŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {audio_file.stat().st_size / 1024 / 1024:.2f} MB")
    print()
    
    print("ðŸ”„ è»¢å†™é–‹å§‹...")
    start_time = time.time()
    
    try:
        result = await service.transcribe_audio(audio_file)
        
        transcribe_time = time.time() - start_time
        audio_duration = result.get("duration_seconds", 0)
        
        print("âœ… è»¢å†™å®Œäº†")
        print()
        print("ðŸ“Š çµæžœ:")
        print(f"   éŸ³å£°é•·: {audio_duration:.2f}ç§’")
        print(f"   å‡¦ç†æ™‚é–“: {transcribe_time:.2f}ç§’")
        
        if audio_duration > 0:
            rtf = transcribe_time / audio_duration
            print(f"   ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼: {rtf:.2f}x")
            print(f"   ï¼ˆ1.0æœªæº€ãŒç†æƒ³ã€å€¤ãŒå°ã•ã„ã»ã©é«˜é€Ÿï¼‰")
        
        print(f"   æ¤œå‡ºè¨€èªž: {result.get('language', 'N/A')}")
        print(f"   ä¿¡é ¼åº¦: {result.get('confidence', 0):.2%}")
        print()
        print(f"ðŸ“ è»¢å†™ãƒ†ã‚­ã‚¹ãƒˆï¼ˆæœ€åˆã®200æ–‡å­—ï¼‰:")
        print(f"   {result.get('text', '')[:200]}...")
        
    except Exception as e:
        print(f"âŒ è»¢å†™å¤±æ•—: {e}")
        return
    
    print()
    print("=" * 60)


async def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    # åŸºæœ¬æ¤œè¨¼
    success = await verify_whisper_implementation()
    
    if not success:
        sys.exit(1)
    
    # ã‚³ãƒžãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚Œã°ãƒ™ãƒ³ãƒãƒžãƒ¼ã‚¯å®Ÿè¡Œ
    if len(sys.argv) > 1:
        audio_file = Path(sys.argv[1])
        await benchmark_transcription(audio_file)
    
    sys.exit(0)


if __name__ == "__main__":
    asyncio.run(main())

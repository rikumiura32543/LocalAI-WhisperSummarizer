#!/bin/bash
# Ollama/Whisperãƒ¢ãƒ‡ãƒ«ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

set -e

# ã‚«ãƒ©ãƒ¼å‡ºåŠ›è¨­å®š
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# è¨­å®šå€¤
OLLAMA_MODEL="${OLLAMA_MODEL:-llama2:7b}"
WHISPER_MODEL="${WHISPER_MODEL:-base}"
OLLAMA_URL="${OLLAMA_BASE_URL:-http://localhost:11434}"

echo -e "${BLUE}M4Aè»¢å†™ã‚·ã‚¹ãƒ†ãƒ  - AI ãƒ¢ãƒ‡ãƒ«ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—${NC}"
echo "=================================="

# Ollamaã‚µãƒ¼ãƒãƒ¼ã®ç¢ºèª
echo -e "${YELLOW}Ollamaã‚µãƒ¼ãƒãƒ¼ã®ç¢ºèªä¸­...${NC}"
if curl -s "${OLLAMA_URL}/api/tags" > /dev/null 2>&1; then
    echo -e "${GREEN}âœ“ Ollamaã‚µãƒ¼ãƒãƒ¼æ¥ç¶šæˆåŠŸ: ${OLLAMA_URL}${NC}"
else
    echo -e "${RED}âœ— Ollamaã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“: ${OLLAMA_URL}${NC}"
    echo "  Ollamaã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã—ã¦ãã ã•ã„: ollama serve"
    exit 1
fi

# Ollamaãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
echo -e "${YELLOW}Ollamaãƒ¢ãƒ‡ãƒ«ã®ç¢ºèªã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰...${NC}"
echo "  ãƒ¢ãƒ‡ãƒ«: ${OLLAMA_MODEL}"

# ãƒ¢ãƒ‡ãƒ«å­˜åœ¨ç¢ºèª
if ollama list | grep -q "${OLLAMA_MODEL}"; then
    echo -e "${GREEN}âœ“ ãƒ¢ãƒ‡ãƒ« '${OLLAMA_MODEL}' ã¯æ—¢ã«åˆ©ç”¨å¯èƒ½ã§ã™${NC}"
else
    echo -e "${YELLOW}ãƒ¢ãƒ‡ãƒ« '${OLLAMA_MODEL}' ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...${NC}"
    echo "  ã“ã‚Œã«ã¯æ•°åˆ†ã‹ã‚‰æ•°ååˆ†ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™"
    
    if ollama pull "${OLLAMA_MODEL}"; then
        echo -e "${GREEN}âœ“ ãƒ¢ãƒ‡ãƒ« '${OLLAMA_MODEL}' ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†${NC}"
    else
        echo -e "${RED}âœ— ãƒ¢ãƒ‡ãƒ« '${OLLAMA_MODEL}' ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ${NC}"
        exit 1
    fi
fi

# Whisperãƒ¢ãƒ‡ãƒ«ã®äº‹å‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆPythonã‚¹ã‚¯ãƒªãƒ—ãƒˆã§å®Ÿè¡Œï¼‰
echo -e "${YELLOW}Whisperãƒ¢ãƒ‡ãƒ«ã®ç¢ºèªã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰...${NC}"
echo "  ãƒ¢ãƒ‡ãƒ«: ${WHISPER_MODEL}"

cat > /tmp/whisper_setup.py << 'EOF'
import sys
import whisper
import os

model_name = os.environ.get('WHISPER_MODEL', 'base')

try:
    print(f"Whisperãƒ¢ãƒ‡ãƒ« '{model_name}' ã‚’èª­ã¿è¾¼ã¿ä¸­...")
    model = whisper.load_model(model_name)
    print(f"âœ“ Whisperãƒ¢ãƒ‡ãƒ« '{model_name}' ã®èª­ã¿è¾¼ã¿å®Œäº†")
    
    # ãƒ¢ãƒ‡ãƒ«æƒ…å ±è¡¨ç¤º
    print(f"  ãƒ‡ãƒã‚¤ã‚¹: {next(model.parameters()).device}")
    print(f"  ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in model.parameters()):,}")
    
except Exception as e:
    print(f"âœ— Whisperãƒ¢ãƒ‡ãƒ« '{model_name}' ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
    sys.exit(1)
EOF

if python3 /tmp/whisper_setup.py; then
    echo -e "${GREEN}âœ“ Whisperãƒ¢ãƒ‡ãƒ«æº–å‚™å®Œäº†${NC}"
else
    echo -e "${RED}âœ— Whisperãƒ¢ãƒ‡ãƒ«ã®æº–å‚™ã«å¤±æ•—ã—ã¾ã—ãŸ${NC}"
    echo "  ä¾å­˜é–¢ä¿‚ã‚’ç¢ºèªã—ã¦ãã ã•ã„: pip install openai-whisper"
fi

# ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
rm -f /tmp/whisper_setup.py

# ãƒ¢ãƒ‡ãƒ«æƒ…å ±è¡¨ç¤º
echo -e "${BLUE}è¨­å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«æƒ…å ±:${NC}"
echo "  Ollama URL: ${OLLAMA_URL}"
echo "  Ollamaãƒ¢ãƒ‡ãƒ«: ${OLLAMA_MODEL}"
echo "  Whisperãƒ¢ãƒ‡ãƒ«: ${WHISPER_MODEL}"

# ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
echo -e "${YELLOW}ãƒ¢ãƒ‡ãƒ«å‹•ä½œãƒ†ã‚¹ãƒˆä¸­...${NC}"

# Ollamaãƒ†ã‚¹ãƒˆ
echo "Ollamaãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­..."
if curl -s -X POST "${OLLAMA_URL}/api/generate" \
  -H "Content-Type: application/json" \
  -d "{\"model\":\"${OLLAMA_MODEL}\",\"prompt\":\"Hello\",\"stream\":false,\"options\":{\"num_predict\":10}}" \
  | grep -q "response"; then
    echo -e "${GREEN}âœ“ Ollamaãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆæˆåŠŸ${NC}"
else
    echo -e "${YELLOW}âš  Ollamaãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆæ™‚é–“ãŒã‹ã‹ã‚‹ãŸã‚ï¼‰${NC}"
fi

echo -e "${GREEN}========================================${NC}"
echo -e "${GREEN}ğŸ‰ AIãƒ¢ãƒ‡ãƒ«ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†ï¼${NC}"
echo -e "${GREEN}========================================${NC}"
echo
echo "æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:"
echo "1. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’èµ·å‹•: python -m app.main"
echo "2. ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯: curl http://localhost:8000/health"
echo "3. APIè©³ç´°ç¢ºèª: curl http://localhost:8000/api/v1/health/detailed"